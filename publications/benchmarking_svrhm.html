<span class="anchor" id="BENCHSVRHM"></span>
<div class="paper">
    <p class="title"><b>Benchmarking human visual search computational models in natural scenes: models comparison and reference datasets</b></p>
    <p><b>Fermín Travi*</b>, Gonzalo Ruarte*, Gastón Bujía, Juan E. Kamienkowski</p>
    <p><i>Shared Visual Representations in Human & Machine Intelligence (SVRHM) Workshop at NeurIPS 2021</i>.</p>
    
    <div class="paper-buttons">
            <a class="button" href="/assets/publications/2021_benchmarking_svrhm/paper.pdf" target="_blank">pdf</a>
        
            <a class="button" href="https://openreview.net/forum?id=ng262VIrK08" target="_blank">openreview</a>
        
            <a class="button" href="/assets/publications/2021_benchmarking_svrhm/poster.png" target="_blank">poster</a>
        
            <a class="button" href="https://github.com/FerminT/VisualSearchBenchmark/tree/SVRHM" target="_blank">code</a>
        
            <a class="button" href="javascript:unhide('bib_visions');">bib</a>
        
    </div>
    
    <div id="bib_visions" class="hidden">
        <pre> 
            @inproceedings{
                travi2021benchmarking,
                title={Benchmarking human visual search computational models in natural scenes: models comparison and reference datasets},
                author={Ferm{\'\i}n Travi and Gonzalo Ruarte and Gaston Bujia and Juan E Kamienkowski},
                booktitle={SVRHM 2021 Workshop @ NeurIPS },
                year={2021},
                url={https://openreview.net/forum?id=ng262VIrK08}
                }
        </pre>
    </div>
</div>