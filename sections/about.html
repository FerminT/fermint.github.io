<div class="docs-section">
    <h4>About</h4>
  
    <p>
    I'm a Senior Researcher at <a href='https://www.microsoft.com/en-us/research/lab/microsoft-research-new-england/' target="_blank" rel="noopener noreferrer">Microsoft Research New England</a>, within the Machine Learning and Statstics group.
    My research seeks to make machine learning more <b>broadly applicable</b> (especially to data-poor applications) and <b>trustworthy</b> (e.g., robust and interpretable). I am particularly interested in the implications of these two directions for applications in the natural and medical sciences. 
  
    </p><p>
    My approach to the first of these goals draws on ideas from statistics, optimization, and applied mathemtics, especially <a href="https://en.wikipedia.org/wiki/Transportation_theory_(mathematics)" target="_blank">optimal transport</a>, which I have used to develop methods to mitigate data scarcity by various types of geometric dataset manipulations: <a href="#InvarOT">alignment</a>, <a href="#OTDD">comparison</a>, <a href="#GWGAN">generation</a>, and <a href="#OTGF">transformation</a>.
    <a href="https://www.microsoft.com/en-us/research/video/directions-in-ml-automating-dataset-comparison-and-manipulation-with-optimal-transport/">This talk</a> provides a high-level overview of this part of my work.
    </p><p>
    As for trustworthy machine learning, I have worked on methods for explaining predictions of <a href="#interpseq">black box models</a>, showed their <a href="#Robust-interpret">lack of robustness</a>, proposed methods to <a href="#SENN">robustify them</a>, and sought inspiration in the social sciences to make them <a href="WOE-HCML">human-centered</a>.
    </p><p>
    In the past, I worked on various aspects of learning with highly-structured data such as text or graphs, ranging from <a href="#WE-metric">learning representations</a> of structured objects, to <a href="#DRNN">generating them</a>, to <a href="#interpseq">interpreting models</a> that operate on them.
  
    <p>
    <b>Update:</b> In July 2023, I will be joining <a href="https://www.seas.harvard.edu/" target="_blank" rel="noopener noreferrer">Harvard SEAS</a> as an Assistant Professor of Computer Science. I will be looking for motivated PhD students and postdocs to join my group. If you are interested in working with me, send me <a href="mailto:dam@seas.harvard.edu">an email</a> with the subject line "[Harvard] Interested in joining your group" and a brief description of your interests and background. 
    </p>
     <!-- to <a href="#SOT">computing distances</a> between them. The latter two aspects form the core themes of my PhD work:
    <UL style="margin:15px;padding:0px;"> -->
  
    <!-- I recently completed my Ph.D. at MIT,
    working on Machine Learning and
    Natural Language Processing under the supervision of <a href="http://people.csail.mit.edu/tommi/"> Tommi
    Jaakkola</a>. My research revolves around learning in structured domains: from <a href="#WE-metric">learning representations</a> of structured objects, to <a href="#DRNN">generating them</a>, to <a href="#interpseq">interpreting models</a> that operate on them, to <a href="#SOT">computing distances</a> between them. The latter two aspects form the core themes of my PhD work:
    <UL style="margin:15px;padding:0px;">
        <li> Optimal transport distances in structured domains </li>
        <li> Principled and robust interpretable machine learning (for structured data, and beyond) </li>
    </UL> -->
    <!-- Other topics that I have worked on in the past are:
    <UL style="margin:15px;padding:0px;">
        <li> Perturbation-based approaches to interpretability in machine learning </li>
        <li> Optimal transport </li>
        <li> Generative adversarial networks</li>
        <li> [Un|semi]-supervised domain adaptation and machine translation.</li>
        <li> Tree and sequence embedding and generation. </li>
        <li> Semantic representations, their manifold structure and geometric properties.</li>
        <li> Optimization: Semidefinite programming, MMW, convex optimization.</li>
    </UL>
    -->
  
    </p>
  </div>